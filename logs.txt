* 
* ==> Audit <==
* |------------|----------------------------|----------|-------|---------|---------------------|---------------------|
|  Command   |            Args            | Profile  | User  | Version |     Start Time      |      End Time       |
|------------|----------------------------|----------|-------|---------|---------------------|---------------------|
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:05 EDT | 19 Jul 25 11:05 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:05 EDT | 19 Jul 25 11:05 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:05 EDT | 19 Jul 25 11:05 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:05 EDT | 19 Jul 25 11:05 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:05 EDT | 19 Jul 25 11:05 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:05 EDT | 19 Jul 25 11:05 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:06 EDT | 19 Jul 25 11:06 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:07 EDT | 19 Jul 25 11:07 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:07 EDT | 19 Jul 25 11:07 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:08 EDT | 19 Jul 25 11:08 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:08 EDT | 19 Jul 25 11:08 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:08 EDT | 19 Jul 25 11:08 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:08 EDT | 19 Jul 25 11:08 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:08 EDT | 19 Jul 25 11:08 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:12 EDT | 19 Jul 25 11:12 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:12 EDT | 19 Jul 25 11:12 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:12 EDT | 19 Jul 25 11:12 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:12 EDT | 19 Jul 25 11:12 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:12 EDT | 19 Jul 25 11:12 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:12 EDT | 19 Jul 25 11:13 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:13 EDT | 19 Jul 25 11:13 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:13 EDT | 19 Jul 25 11:13 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:13 EDT | 19 Jul 25 11:13 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:13 EDT | 19 Jul 25 11:13 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:13 EDT | 19 Jul 25 11:13 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:13 EDT | 19 Jul 25 11:13 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:14 EDT | 19 Jul 25 11:14 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:14 EDT | 19 Jul 25 11:14 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:14 EDT | 19 Jul 25 11:14 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:14 EDT | 19 Jul 25 11:14 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:14 EDT | 19 Jul 25 11:14 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:14 EDT | 19 Jul 25 11:14 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:14 EDT | 19 Jul 25 11:14 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:15 EDT | 19 Jul 25 11:15 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:15 EDT | 19 Jul 25 11:15 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:15 EDT | 19 Jul 25 11:15 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:15 EDT | 19 Jul 25 11:15 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:15 EDT | 19 Jul 25 11:15 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:19 EDT | 19 Jul 25 11:19 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:19 EDT | 19 Jul 25 11:19 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:21 EDT | 19 Jul 25 11:21 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:21 EDT | 19 Jul 25 11:21 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:21 EDT | 19 Jul 25 11:21 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:25 EDT | 19 Jul 25 11:25 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:26 EDT | 19 Jul 25 11:26 EDT |
| docker-env |                            | minikube | saarm | v1.31.2 | 19 Jul 25 11:26 EDT | 19 Jul 25 11:26 EDT |
| addons     | list                       | minikube | saarm | v1.31.2 | 19 Jul 25 11:55 EDT | 19 Jul 25 11:55 EDT |
| addons     | enable csi-hostpath-driver | minikube | saarm | v1.31.2 | 19 Jul 25 11:56 EDT |                     |
| addons     | list                       | minikube | saarm | v1.31.2 | 19 Jul 25 12:01 EDT | 19 Jul 25 12:01 EDT |
| addons     | enable csi-hostpath-driver | minikube | saarm | v1.31.2 | 19 Jul 25 12:02 EDT |                     |
|------------|----------------------------|----------|-------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2025/07/19 11:55:39
Running on machine: saarm-mac
Binary: Built with gc go1.20.7 for darwin/arm64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0719 11:55:39.015691   14750 out.go:296] Setting OutFile to fd 1 ...
I0719 11:55:39.016343   14750 out.go:348] isatty.IsTerminal(1) = true
I0719 11:55:39.016345   14750 out.go:309] Setting ErrFile to fd 2...
I0719 11:55:39.016347   14750 out.go:348] isatty.IsTerminal(2) = true
I0719 11:55:39.016466   14750 root.go:338] Updating PATH: /Users/saarm/.minikube/bin
I0719 11:55:39.016471   14750 oci.go:573] shell is pointing to dockerd inside minikube. will unset to use host

* 
* ==> Docker <==
* Jul 19 15:59:17 minikube dockerd[1051]: time="2025-07-19T15:59:17.696568753Z" level=warning msg="reference for unknown type: " digest="sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8" remote="registry.k8s.io/sig-storage/csi-provisioner@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8"
Jul 19 15:59:17 minikube dockerd[1051]: time="2025-07-19T15:59:17.943503295Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-provisioner/manifests/sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 15:59:17 minikube dockerd[1051]: time="2025-07-19T15:59:17.944845087Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-provisioner/manifests/sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 15:59:18 minikube dockerd[1051]: time="2025-07-19T15:59:18.116168337Z" level=warning msg="reference for unknown type: " digest="sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f" remote="registry.k8s.io/sig-storage/csi-snapshotter@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f"
Jul 19 15:59:18 minikube dockerd[1051]: time="2025-07-19T15:59:18.437386712Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-snapshotter/manifests/sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 15:59:18 minikube dockerd[1051]: time="2025-07-19T15:59:18.440391879Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-snapshotter/manifests/sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 15:59:19 minikube dockerd[1051]: time="2025-07-19T15:59:19.979702463Z" level=warning msg="reference for unknown type: " digest="sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7" remote="registry.k8s.io/sig-storage/csi-resizer@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7"
Jul 19 15:59:20 minikube dockerd[1051]: time="2025-07-19T15:59:20.230139421Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-resizer/manifests/sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 15:59:20 minikube dockerd[1051]: time="2025-07-19T15:59:20.234666463Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-resizer/manifests/sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 15:59:22 minikube dockerd[1051]: time="2025-07-19T15:59:22.010448339Z" level=warning msg="reference for unknown type: " digest="sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b" remote="registry.k8s.io/sig-storage/csi-attacher@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b"
Jul 19 15:59:22 minikube dockerd[1051]: time="2025-07-19T15:59:22.310006464Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-attacher/manifests/sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 15:59:22 minikube dockerd[1051]: time="2025-07-19T15:59:22.312091131Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-attacher/manifests/sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:01 minikube dockerd[1051]: time="2025-07-19T16:02:01.975406677Z" level=warning msg="reference for unknown type: " digest="sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7" remote="registry.k8s.io/sig-storage/csi-resizer@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7"
Jul 19 16:02:02 minikube dockerd[1051]: time="2025-07-19T16:02:02.325548010Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-resizer/manifests/sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:02 minikube dockerd[1051]: time="2025-07-19T16:02:02.327221760Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-resizer/manifests/sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:05 minikube dockerd[1051]: time="2025-07-19T16:02:05.993992679Z" level=warning msg="reference for unknown type: " digest="sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c" remote="registry.k8s.io/sig-storage/csi-external-health-monitor-controller@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c"
Jul 19 16:02:06 minikube dockerd[1051]: time="2025-07-19T16:02:06.275650762Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-external-health-monitor-controller/manifests/sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:06 minikube dockerd[1051]: time="2025-07-19T16:02:06.281141846Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-external-health-monitor-controller/manifests/sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:06 minikube dockerd[1051]: time="2025-07-19T16:02:06.449485471Z" level=warning msg="reference for unknown type: " digest="sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c" remote="registry.k8s.io/sig-storage/csi-node-driver-registrar@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c"
Jul 19 16:02:06 minikube dockerd[1051]: time="2025-07-19T16:02:06.685457512Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-node-driver-registrar/manifests/sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:06 minikube dockerd[1051]: time="2025-07-19T16:02:06.687278804Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-node-driver-registrar/manifests/sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:06 minikube dockerd[1051]: time="2025-07-19T16:02:06.832307554Z" level=warning msg="reference for unknown type: " digest="sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5" remote="registry.k8s.io/sig-storage/hostpathplugin@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5"
Jul 19 16:02:07 minikube dockerd[1051]: time="2025-07-19T16:02:07.096990596Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/hostpathplugin/manifests/sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:07 minikube dockerd[1051]: time="2025-07-19T16:02:07.098638888Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/hostpathplugin/manifests/sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:07 minikube dockerd[1051]: time="2025-07-19T16:02:07.235597596Z" level=warning msg="reference for unknown type: " digest="sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0" remote="registry.k8s.io/sig-storage/livenessprobe@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0"
Jul 19 16:02:07 minikube dockerd[1051]: time="2025-07-19T16:02:07.483077888Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/livenessprobe/manifests/sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:07 minikube dockerd[1051]: time="2025-07-19T16:02:07.484515096Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/livenessprobe/manifests/sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:07 minikube dockerd[1051]: time="2025-07-19T16:02:07.630999055Z" level=warning msg="reference for unknown type: " digest="sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8" remote="registry.k8s.io/sig-storage/csi-provisioner@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8"
Jul 19 16:02:07 minikube dockerd[1051]: time="2025-07-19T16:02:07.929358555Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-provisioner/manifests/sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:07 minikube dockerd[1051]: time="2025-07-19T16:02:07.937942805Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-provisioner/manifests/sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:08 minikube dockerd[1051]: time="2025-07-19T16:02:08.095415346Z" level=warning msg="reference for unknown type: " digest="sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f" remote="registry.k8s.io/sig-storage/csi-snapshotter@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f"
Jul 19 16:02:08 minikube dockerd[1051]: time="2025-07-19T16:02:08.357971847Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-snapshotter/manifests/sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:08 minikube dockerd[1051]: time="2025-07-19T16:02:08.364339430Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-snapshotter/manifests/sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:12 minikube dockerd[1051]: time="2025-07-19T16:02:12.984903543Z" level=warning msg="reference for unknown type: " digest="sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b" remote="registry.k8s.io/sig-storage/csi-attacher@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b"
Jul 19 16:02:13 minikube dockerd[1051]: time="2025-07-19T16:02:13.239972501Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-attacher/manifests/sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:02:13 minikube dockerd[1051]: time="2025-07-19T16:02:13.242618126Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-attacher/manifests/sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:16 minikube dockerd[1051]: time="2025-07-19T16:07:16.993509461Z" level=warning msg="reference for unknown type: " digest="sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7" remote="registry.k8s.io/sig-storage/csi-resizer@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7"
Jul 19 16:07:17 minikube dockerd[1051]: time="2025-07-19T16:07:17.361135045Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-resizer/manifests/sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:17 minikube dockerd[1051]: time="2025-07-19T16:07:17.362507837Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-resizer/manifests/sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:19 minikube dockerd[1051]: time="2025-07-19T16:07:19.126305879Z" level=warning msg="reference for unknown type: " digest="sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b" remote="registry.k8s.io/sig-storage/csi-attacher@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b"
Jul 19 16:07:19 minikube dockerd[1051]: time="2025-07-19T16:07:19.434734046Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-attacher/manifests/sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:19 minikube dockerd[1051]: time="2025-07-19T16:07:19.438861796Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-attacher/manifests/sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:19 minikube dockerd[1051]: time="2025-07-19T16:07:19.588287504Z" level=warning msg="reference for unknown type: " digest="sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c" remote="registry.k8s.io/sig-storage/csi-external-health-monitor-controller@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c"
Jul 19 16:07:19 minikube dockerd[1051]: time="2025-07-19T16:07:19.846048296Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-external-health-monitor-controller/manifests/sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:19 minikube dockerd[1051]: time="2025-07-19T16:07:19.847138754Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-external-health-monitor-controller/manifests/sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:19 minikube dockerd[1051]: time="2025-07-19T16:07:19.980207046Z" level=warning msg="reference for unknown type: " digest="sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c" remote="registry.k8s.io/sig-storage/csi-node-driver-registrar@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c"
Jul 19 16:07:20 minikube dockerd[1051]: time="2025-07-19T16:07:20.242009380Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-node-driver-registrar/manifests/sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:20 minikube dockerd[1051]: time="2025-07-19T16:07:20.243407005Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-node-driver-registrar/manifests/sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:20 minikube dockerd[1051]: time="2025-07-19T16:07:20.376400838Z" level=warning msg="reference for unknown type: " digest="sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5" remote="registry.k8s.io/sig-storage/hostpathplugin@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5"
Jul 19 16:07:20 minikube dockerd[1051]: time="2025-07-19T16:07:20.596290838Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/hostpathplugin/manifests/sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:20 minikube dockerd[1051]: time="2025-07-19T16:07:20.599299755Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/hostpathplugin/manifests/sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:20 minikube dockerd[1051]: time="2025-07-19T16:07:20.752829297Z" level=warning msg="reference for unknown type: " digest="sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0" remote="registry.k8s.io/sig-storage/livenessprobe@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0"
Jul 19 16:07:20 minikube dockerd[1051]: time="2025-07-19T16:07:20.994122797Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/livenessprobe/manifests/sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:20 minikube dockerd[1051]: time="2025-07-19T16:07:20.995221422Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/livenessprobe/manifests/sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:21 minikube dockerd[1051]: time="2025-07-19T16:07:21.155567463Z" level=warning msg="reference for unknown type: " digest="sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8" remote="registry.k8s.io/sig-storage/csi-provisioner@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8"
Jul 19 16:07:21 minikube dockerd[1051]: time="2025-07-19T16:07:21.420571547Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-provisioner/manifests/sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:21 minikube dockerd[1051]: time="2025-07-19T16:07:21.423483172Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-provisioner/manifests/sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:21 minikube dockerd[1051]: time="2025-07-19T16:07:21.583549422Z" level=warning msg="reference for unknown type: " digest="sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f" remote="registry.k8s.io/sig-storage/csi-snapshotter@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f"
Jul 19 16:07:21 minikube dockerd[1051]: time="2025-07-19T16:07:21.865677839Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-snapshotter/manifests/sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\": tls: failed to verify certificate: x509: certificate signed by unknown authority"
Jul 19 16:07:21 minikube dockerd[1051]: time="2025-07-19T16:07:21.869033672Z" level=error msg="Handler for POST /v1.42/images/create returned error: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-snapshotter/manifests/sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\": tls: failed to verify certificate: x509: certificate signed by unknown authority"

* 
* ==> container status <==
* CONTAINER           IMAGE                                                                                                     CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
a86c5ddb5224a       itsthenetwork/nfs-server-alpine@sha256:7fa99ae65c23c5af87dd4300e543a86b119ed15ba61422444207efc7abd0ba20   30 minutes ago      Running             nfs-server                0                   b3077a75dddd4       nfs-server-c8b4c6765-jjglx
350d55551fd8d       busybox@sha256:98ad9d1a2be345201bb0709b0d38655eb1b370145c7d94ca1fe9c421f76e245a                           30 minutes ago      Exited              init-nfs-directories      0                   b3077a75dddd4       nfs-server-c8b4c6765-jjglx
eea2cc0fee7b0       6b108e1075081                                                                                             41 minutes ago      Running             vr-frontend               0                   d4bb1d8cfd0b2       loco-loco-vr-597f8b596-dz9xk
3eab881590134       dadacf1e6b8b5                                                                                             47 minutes ago      Running             frontend                  0                   1521e87d46591       loco-loco-frontend-6d98b96875-j6lkk
c5bdcdeb3d2b6       ced66612a2825                                                                                             About an hour ago   Running             backend                   0                   e20b2d7d78b30       loco-loco-backend-8cbc68c94-p5s24
770f516908d06       ba04bb24b9575                                                                                             About an hour ago   Running             storage-provisioner       0                   cb8a89c886d74       storage-provisioner
f337bfc41cf5f       97e04611ad434                                                                                             About an hour ago   Running             coredns                   0                   635cda3c3d69d       coredns-5d78c9869d-ks9zw
a140485af1f21       532e5a30e948f                                                                                             About an hour ago   Running             kube-proxy                0                   6203ae22628ce       kube-proxy-wvwxz
d4c00fdb3ce19       6eb63895cb67f                                                                                             About an hour ago   Running             kube-scheduler            0                   3cb1f71d05620       kube-scheduler-minikube
641f81c49695d       64aece92d6bde                                                                                             About an hour ago   Running             kube-apiserver            0                   4c0f57d90cb13       kube-apiserver-minikube
750406026e596       389f6f052cf83                                                                                             About an hour ago   Running             kube-controller-manager   0                   72c8fabd40344       kube-controller-manager-minikube
7d34c949d031f       24bc64e911039                                                                                             About an hour ago   Running             etcd                      0                   ec27ec6a3e7dc       etcd-minikube

* 
* ==> coredns [f337bfc41cf5] <==
* [INFO] plugin/ready: Still waiting on: "kubernetes"
.:53
[INFO] plugin/reload: Running configuration SHA512 = f869070685748660180df1b7a47d58cdafcf2f368266578c062d1151dc2c900964aecc5975e8882e6de6fdfb6460463e30ebfaad2ec8f0c3c6436f80225b3b5b
CoreDNS-1.10.1
linux/arm64, go1.20, 055b2c3
[INFO] 127.0.0.1:39020 - 35329 "HINFO IN 306636072804213502.741898993201263605. udp 55 false 512" NXDOMAIN qr,rd,ra 55 0.117309583s
[INFO] 10.244.0.10:53219 - 63001 "A IN loco-loco-backend.loco.svc.cluster.local. udp 58 false 512" NOERROR qr,aa,rd 114 0.000513667s
[INFO] 10.244.0.9:38649 - 44235 "A IN loco-loco-backend.loco.svc.cluster.local. udp 58 false 512" NOERROR qr,aa,rd 114 0.000187709s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=arm64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=arm64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=fd7ecd9c4599bef9f04c0986c4a0187f98a4396e
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2025_07_19T10_50_17_0700
                    minikube.k8s.io/version=v1.31.2
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Sat, 19 Jul 2025 14:50:14 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Sat, 19 Jul 2025 16:08:33 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Sat, 19 Jul 2025 16:03:49 +0000   Sat, 19 Jul 2025 14:50:13 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Sat, 19 Jul 2025 16:03:49 +0000   Sat, 19 Jul 2025 14:50:13 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Sat, 19 Jul 2025 16:03:49 +0000   Sat, 19 Jul 2025 14:50:13 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Sat, 19 Jul 2025 16:03:49 +0000   Sat, 19 Jul 2025 14:50:14 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                10
  ephemeral-storage:  61202244Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             16360396Ki
  pods:               110
Allocatable:
  cpu:                10
  ephemeral-storage:  61202244Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             16360396Ki
  pods:               110
System Info:
  Machine ID:                 171d358574264b9c9dc46e18f85c4289
  System UUID:                171d358574264b9c9dc46e18f85c4289
  Boot ID:                    f17a0f82-a3b4-4a27-85d1-eedf59cc38cf
  Kernel Version:             6.6.12-linuxkit
  OS Image:                   Ubuntu 22.04.2 LTS
  Operating System:           linux
  Architecture:               arm64
  Container Runtime Version:  docker://24.0.4
  Kubelet Version:            v1.27.4
  Kube-Proxy Version:         v1.27.4
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (15 in total)
  Namespace                   Name                                   CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                   ------------  ----------  ---------------  -------------  ---
  kube-system                 coredns-5d78c9869d-ks9zw               100m (1%!)(MISSING)     0 (0%!)(MISSING)      70Mi (0%!)(MISSING)        170Mi (1%!)(MISSING)     78m
  kube-system                 csi-hostpath-attacher-0                0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         12m
  kube-system                 csi-hostpath-resizer-0                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         12m
  kube-system                 csi-hostpathplugin-fxglc               0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         12m
  kube-system                 etcd-minikube                          100m (1%!)(MISSING)     0 (0%!)(MISSING)      100Mi (0%!)(MISSING)       0 (0%!)(MISSING)         78m
  kube-system                 kube-apiserver-minikube                250m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         78m
  kube-system                 kube-controller-manager-minikube       200m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         78m
  kube-system                 kube-proxy-wvwxz                       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         78m
  kube-system                 kube-scheduler-minikube                100m (1%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         78m
  kube-system                 storage-provisioner                    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         78m
  loco                        loco-loco-backend-8cbc68c94-p5s24      0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         64m
  loco                        loco-loco-emulator-0                   250m (2%!)(MISSING)     1 (10%!)(MISSING)     0 (0%!)(MISSING)           0 (0%!)(MISSING)         29m
  loco                        loco-loco-frontend-6d98b96875-j6lkk    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         64m
  loco                        loco-loco-vr-597f8b596-dz9xk           0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         64m
  loco                        nfs-server-c8b4c6765-jjglx             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         30m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                1 (10%!)(MISSING)     1 (10%!)(MISSING)
  memory             170Mi (1%!)(MISSING)  170Mi (1%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-32Mi     0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-64Ki     0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:              <none>

* 
* ==> dmesg <==
* [  +0.000002]  out_of_memory+0xe4/0x358
[  +0.000002]  mem_cgroup_out_of_memory+0x134/0x158
[  +0.000003]  try_charge_memcg+0x5f0/0x6d8
[  +0.000002]  charge_memcg+0x50/0xc0
[  +0.000002]  __mem_cgroup_charge+0x40/0x90
[  +0.000002]  __handle_mm_fault+0x59c/0xd00
[  +0.000003]  handle_mm_fault+0x16c/0x290
[  +0.000002]  do_page_fault+0x158/0x498
[  +0.000003]  do_translation_fault+0x90/0xb0
[  +0.000001]  do_mem_abort+0x4c/0xa8
[  +0.000001]  el0_da+0x48/0xf0
[  +0.000003]  el0t_64_sync_handler+0xb4/0x130
[  +0.000001]  el0t_64_sync+0x190/0x198
[  +0.000288] Memory cgroup out of memory: Killed process 200904 (rpc.mountd) total-vm:504060kB, anon-rss:55924kB, file-rss:216kB, shmem-rss:0kB, UID:0 pgtables:204kB oom_score_adj:1000
[  +2.218359] rpcinfo invoked oom-killer: gfp_mask=0xcc0(GFP_KERNEL), order=0, oom_score_adj=1000
[  +0.000010] CPU: 3 PID: 201002 Comm: rpcinfo Tainted: G           O       6.6.12-linuxkit #1
[  +0.000003] Call trace:
[  +0.000001]  dump_backtrace+0x98/0xf8
[  +0.000005]  show_stack+0x20/0x38
[  +0.000001]  dump_stack_lvl+0x48/0x60
[  +0.000004]  dump_stack+0x18/0x28
[  +0.000001]  dump_header+0x50/0x228
[  +0.000004]  oom_kill_process+0x148/0x300
[  +0.000002]  out_of_memory+0xe4/0x358
[  +0.000001]  mem_cgroup_out_of_memory+0x134/0x158
[  +0.000003]  try_charge_memcg+0x5f0/0x6d8
[  +0.000007]  charge_memcg+0x50/0xc0
[  +0.000002]  __mem_cgroup_charge+0x40/0x90
[  +0.000002]  __handle_mm_fault+0x59c/0xd00
[  +0.000004]  handle_mm_fault+0x16c/0x290
[  +0.000001]  do_page_fault+0x158/0x498
[  +0.000003]  do_translation_fault+0x90/0xb0
[  +0.000001]  do_mem_abort+0x4c/0xa8
[  +0.000001]  el0_da+0x48/0xf0
[  +0.000002]  el0t_64_sync_handler+0xb4/0x130
[  +0.000002]  el0t_64_sync+0x190/0x198
[  +0.000339] Memory cgroup out of memory: Killed process 200959 (rpc.mountd) total-vm:504060kB, anon-rss:55924kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:204kB oom_score_adj:1000
[  +0.275339] docker invoked oom-killer: gfp_mask=0xcc0(GFP_KERNEL), order=0, oom_score_adj=0
[  +0.000008] CPU: 5 PID: 201055 Comm: docker Tainted: G           O       6.6.12-linuxkit #1
[  +0.000003] Call trace:
[  +0.000001]  dump_backtrace+0x98/0xf8
[  +0.000004]  show_stack+0x20/0x38
[  +0.000001]  dump_stack_lvl+0x48/0x60
[  +0.000003]  dump_stack+0x18/0x28
[  +0.000001]  dump_header+0x50/0x228
[  +0.000003]  oom_kill_process+0x148/0x300
[  +0.000002]  out_of_memory+0xe4/0x358
[  +0.000001]  mem_cgroup_out_of_memory+0x134/0x158
[  +0.000003]  try_charge_memcg+0x5f0/0x6d8
[  +0.000002]  charge_memcg+0x50/0xc0
[  +0.000001]  __mem_cgroup_charge+0x40/0x90
[  +0.000002]  __handle_mm_fault+0x59c/0xd00
[  +0.000004]  handle_mm_fault+0x16c/0x290
[  +0.000002]  do_page_fault+0x158/0x498
[  +0.000003]  do_translation_fault+0x90/0xb0
[  +0.000001]  do_mem_abort+0x4c/0xa8
[  +0.000001]  el0_da+0x48/0xf0
[  +0.000002]  el0t_64_sync_handler+0xb4/0x130
[  +0.000002]  el0t_64_sync+0x190/0x198
[  +0.000293] Memory cgroup out of memory: Killed process 201032 (rpc.mountd) total-vm:504060kB, anon-rss:55924kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:204kB oom_score_adj:1000

* 
* ==> etcd [7d34c949d031] <==
* {"level":"info","ts":"2025-07-19T14:50:13.538Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 2"}
{"level":"info","ts":"2025-07-19T14:50:13.538Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 2"}
{"level":"info","ts":"2025-07-19T14:50:13.538Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 2"}
{"level":"info","ts":"2025-07-19T14:50:13.538Z","caller":"etcdserver/server.go:2062","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2025-07-19T14:50:13.538Z","caller":"etcdserver/server.go:2571","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2025-07-19T14:50:13.539Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2025-07-19T14:50:13.539Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2025-07-19T14:50:13.539Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2025-07-19T14:50:13.539Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2025-07-19T14:50:13.539Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","cluster-version":"3.5"}
{"level":"info","ts":"2025-07-19T14:50:13.539Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2025-07-19T14:50:13.539Z","caller":"etcdserver/server.go:2595","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2025-07-19T14:50:13.540Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"192.168.49.2:2379"}
{"level":"info","ts":"2025-07-19T14:50:13.540Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"warn","ts":"2025-07-19T14:56:52.128Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"117.993417ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" ","response":"range_response_count:1 size:601"}
{"level":"info","ts":"2025-07-19T14:56:52.128Z","caller":"traceutil/trace.go:171","msg":"trace[1552612129] range","detail":"{range_begin:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; range_end:; response_count:1; response_revision:970; }","duration":"119.122792ms","start":"2025-07-19T14:56:52.009Z","end":"2025-07-19T14:56:52.128Z","steps":["trace[1552612129] 'range keys from bolt db'  (duration: 117.589208ms)"],"step_count":1}
{"level":"info","ts":"2025-07-19T15:00:13.522Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":874}
{"level":"info","ts":"2025-07-19T15:00:13.543Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":874,"took":"21.011375ms","hash":2146826108}
{"level":"info","ts":"2025-07-19T15:00:13.543Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":2146826108,"revision":874,"compact-revision":-1}
{"level":"info","ts":"2025-07-19T15:05:13.527Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":1246}
{"level":"info","ts":"2025-07-19T15:05:13.531Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":1246,"took":"3.104125ms","hash":1859900365}
{"level":"info","ts":"2025-07-19T15:05:13.531Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1859900365,"revision":1246,"compact-revision":874}
{"level":"info","ts":"2025-07-19T15:10:13.531Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":1677}
{"level":"info","ts":"2025-07-19T15:10:13.556Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":1677,"took":"24.234125ms","hash":3312596733}
{"level":"info","ts":"2025-07-19T15:10:13.556Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3312596733,"revision":1677,"compact-revision":1246}
{"level":"info","ts":"2025-07-19T15:12:14.779Z","caller":"traceutil/trace.go:171","msg":"trace[1645472155] transaction","detail":"{read_only:false; response_revision:2089; number_of_response:1; }","duration":"272.512334ms","start":"2025-07-19T15:12:14.507Z","end":"2025-07-19T15:12:14.779Z","steps":["trace[1645472155] 'process raft request'  (duration: 272.419042ms)"],"step_count":1}
{"level":"info","ts":"2025-07-19T15:12:39.177Z","caller":"traceutil/trace.go:171","msg":"trace[959484511] transaction","detail":"{read_only:false; response_revision:2109; number_of_response:1; }","duration":"146.927375ms","start":"2025-07-19T15:12:39.031Z","end":"2025-07-19T15:12:39.177Z","steps":["trace[959484511] 'process raft request'  (duration: 146.325625ms)"],"step_count":1}
{"level":"info","ts":"2025-07-19T15:15:13.535Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":1990}
{"level":"info","ts":"2025-07-19T15:15:13.592Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":1990,"took":"57.140083ms","hash":3991213685}
{"level":"info","ts":"2025-07-19T15:15:13.592Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3991213685,"revision":1990,"compact-revision":1677}
{"level":"info","ts":"2025-07-19T15:20:13.552Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":2243}
{"level":"info","ts":"2025-07-19T15:20:13.600Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":2243,"took":"47.7195ms","hash":1978416331}
{"level":"info","ts":"2025-07-19T15:20:13.600Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1978416331,"revision":2243,"compact-revision":1990}
{"level":"info","ts":"2025-07-19T15:25:13.556Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":2493}
{"level":"info","ts":"2025-07-19T15:25:13.584Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":2493,"took":"26.88025ms","hash":104040573}
{"level":"info","ts":"2025-07-19T15:25:13.584Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":104040573,"revision":2493,"compact-revision":2243}
{"level":"info","ts":"2025-07-19T15:30:13.585Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":2749}
{"level":"info","ts":"2025-07-19T15:30:13.603Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":2749,"took":"18.324459ms","hash":1022745926}
{"level":"info","ts":"2025-07-19T15:30:13.603Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1022745926,"revision":2749,"compact-revision":2493}
{"level":"info","ts":"2025-07-19T15:35:13.592Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":3018}
{"level":"info","ts":"2025-07-19T15:35:13.614Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":3018,"took":"21.909167ms","hash":1714764944}
{"level":"info","ts":"2025-07-19T15:35:13.614Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1714764944,"revision":3018,"compact-revision":2749}
{"level":"info","ts":"2025-07-19T15:40:13.602Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":3289}
{"level":"info","ts":"2025-07-19T15:40:13.627Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":3289,"took":"21.64925ms","hash":1839432985}
{"level":"info","ts":"2025-07-19T15:40:13.627Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1839432985,"revision":3289,"compact-revision":3018}
{"level":"info","ts":"2025-07-19T15:45:13.619Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":3595}
{"level":"info","ts":"2025-07-19T15:45:13.645Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":3595,"took":"24.928291ms","hash":1428306278}
{"level":"info","ts":"2025-07-19T15:45:13.645Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1428306278,"revision":3595,"compact-revision":3289}
{"level":"info","ts":"2025-07-19T15:50:13.648Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":3839}
{"level":"info","ts":"2025-07-19T15:50:13.663Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":3839,"took":"15.232875ms","hash":1110109210}
{"level":"info","ts":"2025-07-19T15:50:13.663Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1110109210,"revision":3839,"compact-revision":3595}
{"level":"info","ts":"2025-07-19T15:55:13.673Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":4086}
{"level":"info","ts":"2025-07-19T15:55:13.693Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":4086,"took":"19.942542ms","hash":1588826780}
{"level":"info","ts":"2025-07-19T15:55:13.693Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1588826780,"revision":4086,"compact-revision":3839}
{"level":"info","ts":"2025-07-19T16:00:13.687Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":4331}
{"level":"info","ts":"2025-07-19T16:00:13.702Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":4331,"took":"14.136333ms","hash":1222110367}
{"level":"info","ts":"2025-07-19T16:00:13.702Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1222110367,"revision":4331,"compact-revision":4086}
{"level":"info","ts":"2025-07-19T16:05:13.710Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":4749}
{"level":"info","ts":"2025-07-19T16:05:13.739Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":4749,"took":"29.439375ms","hash":659406863}
{"level":"info","ts":"2025-07-19T16:05:13.739Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":659406863,"revision":4749,"compact-revision":4331}

* 
* ==> kernel <==
*  16:08:35 up  1:20,  0 users,  load average: 3.91, 4.17, 4.31
Linux minikube 6.6.12-linuxkit #1 SMP Thu Feb  8 06:36:34 UTC 2024 aarch64 aarch64 aarch64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.2 LTS"

* 
* ==> kube-apiserver [641f81c49695] <==
* I0719 14:50:14.270447       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0719 14:50:14.271006       1 controller.go:624] quota admission added evaluator for: namespaces
I0719 14:50:14.442582       1 controller.go:624] quota admission added evaluator for: leases.coordination.k8s.io
I0719 14:50:15.043895       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I0719 14:50:15.186582       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I0719 14:50:15.189361       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I0719 14:50:15.189376       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0719 14:50:15.439848       1 controller.go:624] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0719 14:50:15.468510       1 controller.go:624] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0719 14:50:15.584766       1 alloc.go:330] "allocated clusterIPs" service="default/kubernetes" clusterIPs=map[IPv4:10.96.0.1]
W0719 14:50:15.589189       1 lease.go:251] Resetting endpoints for master service "kubernetes" to [192.168.49.2]
I0719 14:50:15.589783       1 controller.go:624] quota admission added evaluator for: endpoints
I0719 14:50:15.591740       1 controller.go:624] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0719 14:50:16.206348       1 controller.go:624] quota admission added evaluator for: serviceaccounts
I0719 14:50:16.798348       1 controller.go:624] quota admission added evaluator for: deployments.apps
I0719 14:50:16.804904       1 alloc.go:330] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs=map[IPv4:10.96.0.10]
I0719 14:50:16.813366       1 controller.go:624] quota admission added evaluator for: daemonsets.apps
I0719 14:50:27.422790       1 alloc.go:330] "allocated clusterIPs" service="loco/loco-loco-vr" clusterIPs=map[IPv4:10.100.124.213]
I0719 14:50:27.424857       1 alloc.go:330] "allocated clusterIPs" service="loco/nfs-server" clusterIPs=map[IPv4:10.100.197.165]
I0719 14:50:27.427817       1 alloc.go:330] "allocated clusterIPs" service="loco/loco-loco-backend" clusterIPs=map[IPv4:10.111.66.200]
I0719 14:50:27.429994       1 alloc.go:330] "allocated clusterIPs" service="loco/loco-loco-frontend" clusterIPs=map[IPv4:10.106.49.72]
E0719 14:50:27.439477       1 fieldmanager.go:152] "[SHOULD NOT HAPPEN] failed to update managedFields" err=<
	failed to convert new object (loco/loco-loco-emulator; apps/v1, Kind=StatefulSet) to smd typed: errors:
	  .spec.template.spec.containers[name="emulator"].env: duplicate entries for key [name="USE_PREBUILT_SNAPSHOT"]
	  .spec.template.spec.containers[name="emulator"].env: duplicate entries for key [name="SNAPSHOT_REGISTRY"]
	  .spec.template.spec.containers[name="emulator"].env: duplicate entries for key [name="SNAPSHOT_TAG"]
 > versionKind="/, Kind=" namespace="loco" name="loco-loco-emulator"
I0719 14:50:27.439646       1 controller.go:624] quota admission added evaluator for: statefulsets.apps
I0719 14:50:29.461593       1 controller.go:624] quota admission added evaluator for: controllerrevisions.apps
I0719 14:50:29.762208       1 controller.go:624] quota admission added evaluator for: replicasets.apps
E0719 14:50:29.963085       1 fieldmanager.go:152] "[SHOULD NOT HAPPEN] failed to update managedFields" err=<
	failed to convert new object (loco/loco-loco-emulator-0; /v1, Kind=Pod) to smd typed: errors:
	  .spec.containers[name="emulator"].env: duplicate entries for key [name="USE_PREBUILT_SNAPSHOT"]
	  .spec.containers[name="emulator"].env: duplicate entries for key [name="SNAPSHOT_REGISTRY"]
	  .spec.containers[name="emulator"].env: duplicate entries for key [name="SNAPSHOT_TAG"]
 > versionKind="/, Kind=" namespace="loco" name="loco-loco-emulator-0"
E0719 14:58:20.382293       1 fieldmanager.go:152] "[SHOULD NOT HAPPEN] failed to update managedFields" err=<
	failed to convert new object (loco/loco-loco-emulator-0; /v1, Kind=Pod) to smd typed: errors:
	  .spec.containers[name="emulator"].env: duplicate entries for key [name="USE_PREBUILT_SNAPSHOT"]
	  .spec.containers[name="emulator"].env: duplicate entries for key [name="SNAPSHOT_REGISTRY"]
	  .spec.containers[name="emulator"].env: duplicate entries for key [name="SNAPSHOT_TAG"]
 > versionKind="/, Kind=" namespace="loco" name="loco-loco-emulator-0"
I0719 15:03:58.909292       1 alloc.go:330] "allocated clusterIPs" service="loco/loco-loco-backend" clusterIPs=map[IPv4:10.111.124.154]
I0719 15:03:58.923435       1 alloc.go:330] "allocated clusterIPs" service="loco/loco-loco-frontend" clusterIPs=map[IPv4:10.111.158.78]
I0719 15:03:58.932355       1 alloc.go:330] "allocated clusterIPs" service="loco/nfs-server" clusterIPs=map[IPv4:10.111.127.115]
I0719 15:03:58.943386       1 alloc.go:330] "allocated clusterIPs" service="loco/loco-loco-vr" clusterIPs=map[IPv4:10.110.49.99]
E0719 15:03:59.026679       1 fieldmanager.go:152] "[SHOULD NOT HAPPEN] failed to update managedFields" err=<
	failed to convert new object (loco/loco-loco-emulator; apps/v1, Kind=StatefulSet) to smd typed: errors:
	  .spec.template.spec.containers[name="emulator"].env: duplicate entries for key [name="USE_PREBUILT_SNAPSHOT"]
	  .spec.template.spec.containers[name="emulator"].env: duplicate entries for key [name="SNAPSHOT_REGISTRY"]
	  .spec.template.spec.containers[name="emulator"].env: duplicate entries for key [name="SNAPSHOT_TAG"]
 > versionKind="/, Kind=" namespace="loco" name="loco-loco-emulator"
E0719 15:38:55.431959       1 fieldmanager.go:152] "[SHOULD NOT HAPPEN] failed to update managedFields" err=<
	failed to convert new object (loco/loco-loco-emulator-0; /v1, Kind=Pod) to smd typed: errors:
	  .spec.containers[name="emulator"].env: duplicate entries for key [name="USE_PREBUILT_SNAPSHOT"]
	  .spec.containers[name="emulator"].env: duplicate entries for key [name="SNAPSHOT_REGISTRY"]
	  .spec.containers[name="emulator"].env: duplicate entries for key [name="SNAPSHOT_TAG"]
 > versionKind="/, Kind=" namespace="loco" name="loco-loco-emulator-0"
I0719 15:56:25.972562       1 alloc.go:330] "allocated clusterIPs" service="kube-system/csi-hostpath-attacher" clusterIPs=map[IPv4:10.108.26.165]
I0719 15:56:26.081074       1 alloc.go:330] "allocated clusterIPs" service="kube-system/csi-hostpath-resizer" clusterIPs=map[IPv4:10.97.183.145]

* 
* ==> kube-controller-manager [750406026e59] <==
* I0719 15:17:29.258618       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:17:44.260386       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:17:59.260931       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:18:14.263675       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:18:29.265583       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:18:44.266770       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:18:59.277243       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:19:14.276915       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:19:29.276636       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:19:44.277409       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:19:59.279138       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:20:14.281024       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:20:29.281348       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:20:44.281665       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:20:59.283051       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:21:14.282834       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:21:29.293253       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:21:44.293548       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:21:59.294013       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:22:14.294231       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:22:29.298814       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:22:44.309169       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:22:59.311442       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:23:14.309593       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:23:29.310790       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:23:44.308886       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:23:59.312156       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:24:14.315445       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:24:29.315280       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:24:44.315349       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:24:59.315897       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:25:14.316867       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:25:29.316955       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:25:44.318624       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:25:59.319289       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:26:14.319431       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:26:29.323064       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:26:44.323313       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:26:59.325554       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:27:14.326276       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:27:29.328166       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:27:44.328260       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:27:59.329526       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:28:14.329827       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:28:29.332802       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:28:44.333667       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:28:59.335291       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:29:14.336058       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:29:29.337270       1 event.go:307] "Event occurred" object="loco/win98-disk" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="FailedBinding" message="volume \"win98-disk-pv\" already bound to a different claim."
I0719 15:35:01.737819       1 event.go:307] "Event occurred" object="loco/nfs-server-6644c89c4b" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: nfs-server-6644c89c4b-rqp22"
I0719 15:38:08.860776       1 event.go:307] "Event occurred" object="loco/nfs-server" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set nfs-server-c8b4c6765 to 1"
I0719 15:38:08.867408       1 event.go:307] "Event occurred" object="loco/nfs-server-c8b4c6765" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: nfs-server-c8b4c6765-jjglx"
I0719 15:38:12.963099       1 event.go:307] "Event occurred" object="loco/nfs-server" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled down replica set nfs-server-6644c89c4b to 0 from 1"
I0719 15:38:12.973312       1 event.go:307] "Event occurred" object="loco/nfs-server-6644c89c4b" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: nfs-server-6644c89c4b-rqp22"
I0719 15:38:55.430021       1 event.go:307] "Event occurred" object="loco/loco-loco-emulator" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet loco/loco-loco-emulator is recreating failed Pod loco-loco-emulator-0"
I0719 15:38:55.431207       1 event.go:307] "Event occurred" object="loco/loco-loco-emulator" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod loco-loco-emulator-0 in StatefulSet loco-loco-emulator successful"
I0719 15:38:55.437647       1 event.go:307] "Event occurred" object="loco/loco-loco-emulator" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod loco-loco-emulator-0 in StatefulSet loco-loco-emulator successful"
I0719 15:56:25.989064       1 event.go:307] "Event occurred" object="kube-system/csi-hostpath-attacher" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod csi-hostpath-attacher-0 in StatefulSet csi-hostpath-attacher successful"
I0719 15:56:26.083995       1 event.go:307] "Event occurred" object="kube-system/csi-hostpathplugin" fieldPath="" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: csi-hostpathplugin-fxglc"
I0719 15:56:26.105694       1 event.go:307] "Event occurred" object="kube-system/csi-hostpath-resizer" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod csi-hostpath-resizer-0 in StatefulSet csi-hostpath-resizer successful"

* 
* ==> kube-proxy [a140485af1f2] <==
* I0719 14:50:30.563049       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I0719 14:50:30.563120       1 server_others.go:110] "Detected node IP" address="192.168.49.2"
I0719 14:50:30.563143       1 server_others.go:554] "Using iptables proxy"
I0719 14:50:30.576755       1 server_others.go:192] "Using iptables Proxier"
I0719 14:50:30.576782       1 server_others.go:199] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I0719 14:50:30.576786       1 server_others.go:200] "Creating dualStackProxier for iptables"
I0719 14:50:30.576793       1 server_others.go:484] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, defaulting to no-op detect-local for IPv6"
I0719 14:50:30.576810       1 proxier.go:253] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0719 14:50:30.577185       1 server.go:658] "Version info" version="v1.27.4"
I0719 14:50:30.577197       1 server.go:660] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0719 14:50:30.577805       1 config.go:188] "Starting service config controller"
I0719 14:50:30.577820       1 shared_informer.go:311] Waiting for caches to sync for service config
I0719 14:50:30.577805       1 config.go:315] "Starting node config controller"
I0719 14:50:30.577829       1 shared_informer.go:311] Waiting for caches to sync for node config
I0719 14:50:30.577809       1 config.go:97] "Starting endpoint slice config controller"
I0719 14:50:30.577834       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0719 14:50:30.679063       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0719 14:50:30.679099       1 shared_informer.go:318] Caches are synced for service config
I0719 14:50:30.679320       1 shared_informer.go:318] Caches are synced for node config

* 
* ==> kube-scheduler [d4c00fdb3ce1] <==
* W0719 14:50:14.184519       1 authentication.go:368] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0719 14:50:14.184524       1 authentication.go:369] Continuing without authentication configuration. This may treat all requests as anonymous.
W0719 14:50:14.184528       1 authentication.go:370] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0719 14:50:14.191820       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.27.4"
I0719 14:50:14.191839       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0719 14:50:14.192777       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I0719 14:50:14.192793       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0719 14:50:14.192805       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0719 14:50:14.192806       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
W0719 14:50:14.193861       1 reflector.go:533] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0719 14:50:14.193900       1 reflector.go:148] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0719 14:50:14.193919       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0719 14:50:14.193938       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0719 14:50:14.193939       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0719 14:50:14.193948       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0719 14:50:14.193965       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0719 14:50:14.193969       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0719 14:50:14.193985       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0719 14:50:14.193986       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0719 14:50:14.193990       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0719 14:50:14.193991       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0719 14:50:14.193997       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0719 14:50:14.194014       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0719 14:50:14.194018       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0719 14:50:14.194022       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0719 14:50:14.194005       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0719 14:50:14.194029       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0719 14:50:14.194006       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0719 14:50:14.194037       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0719 14:50:14.194024       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0719 14:50:14.194054       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0719 14:50:14.194037       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0719 14:50:14.194043       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0719 14:50:14.194063       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0719 14:50:14.194066       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0719 14:50:14.194068       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0719 14:50:14.194045       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0719 14:50:14.194085       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0719 14:50:14.194109       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0719 14:50:15.043011       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0719 14:50:15.043056       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0719 14:50:15.114489       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0719 14:50:15.127688       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0719 14:50:15.128840       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0719 14:50:15.128887       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0719 14:50:15.129724       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0719 14:50:15.129785       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0719 14:50:15.146243       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0719 14:50:15.146271       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0719 14:50:15.169820       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0719 14:50:15.169852       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0719 14:50:15.233805       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0719 14:50:15.233828       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0719 14:50:15.346742       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0719 14:50:15.346769       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0719 14:50:15.349686       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0719 14:50:15.349710       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0719 14:50:15.354479       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0719 14:50:15.354503       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
I0719 14:50:15.793088       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* Jul 19 16:06:43 minikube kubelet[2393]: E0719 16:06:43.827565    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-attacher\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\\\"\"" pod="kube-system/csi-hostpath-attacher-0" podUID=84a0ed60-2130-4d0a-a4f0-2f9e2d0a0796
Jul 19 16:06:50 minikube kubelet[2393]: E0719 16:06:50.832616    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-resizer\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\\\"\"" pod="kube-system/csi-hostpath-resizer-0" podUID=141cbb01-a17d-4d07-9f2b-8b3f2c341cd6
Jul 19 16:06:51 minikube kubelet[2393]: E0719 16:06:51.828448    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"csi-external-health-monitor-controller\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-external-health-monitor-controller:v0.7.0@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\\\"\", failed to \"StartContainer\" for \"node-driver-registrar\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.6.0@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\\\"\", failed to \"StartContainer\" for \"hostpath\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/hostpathplugin:v1.9.0@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\\\"\", failed to \"StartContainer\" for \"liveness-probe\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/livenessprobe:v2.8.0@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\\\"\", failed to \"StartContainer\" for \"csi-provisioner\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-provisioner:v3.3.0@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\\\"\", failed to \"StartContainer\" for \"csi-snapshotter\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\\\"\"]" pod="kube-system/csi-hostpathplugin-fxglc" podUID=5cfdaa53-000f-4685-a113-2a7771f51bb4
Jul 19 16:06:56 minikube kubelet[2393]: E0719 16:06:56.823014    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-attacher\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\\\"\"" pod="kube-system/csi-hostpath-attacher-0" podUID=84a0ed60-2130-4d0a-a4f0-2f9e2d0a0796
Jul 19 16:07:01 minikube kubelet[2393]: E0719 16:07:01.826388    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-resizer\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\\\"\"" pod="kube-system/csi-hostpath-resizer-0" podUID=141cbb01-a17d-4d07-9f2b-8b3f2c341cd6
Jul 19 16:07:03 minikube kubelet[2393]: E0719 16:07:03.833413    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"csi-external-health-monitor-controller\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-external-health-monitor-controller:v0.7.0@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\\\"\", failed to \"StartContainer\" for \"node-driver-registrar\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.6.0@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\\\"\", failed to \"StartContainer\" for \"hostpath\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/hostpathplugin:v1.9.0@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\\\"\", failed to \"StartContainer\" for \"liveness-probe\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/livenessprobe:v2.8.0@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\\\"\", failed to \"StartContainer\" for \"csi-provisioner\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-provisioner:v3.3.0@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\\\"\", failed to \"StartContainer\" for \"csi-snapshotter\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\\\"\"]" pod="kube-system/csi-hostpathplugin-fxglc" podUID=5cfdaa53-000f-4685-a113-2a7771f51bb4
Jul 19 16:07:07 minikube kubelet[2393]: E0719 16:07:07.823749    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-attacher\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\\\"\"" pod="kube-system/csi-hostpath-attacher-0" podUID=84a0ed60-2130-4d0a-a4f0-2f9e2d0a0796
Jul 19 16:07:17 minikube kubelet[2393]: E0719 16:07:17.362905    2393 remote_image.go:167] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-resizer/manifests/sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7"
Jul 19 16:07:17 minikube kubelet[2393]: E0719 16:07:17.362941    2393 kuberuntime_image.go:53] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-resizer/manifests/sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7"
Jul 19 16:07:17 minikube kubelet[2393]: E0719 16:07:17.363017    2393 kuberuntime_manager.go:1212] container &Container{Name:csi-resizer,Image:registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7,Command:[],Args:[-v=5 -csi-address=/csi/csi.sock],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:socket-dir,ReadOnly:false,MountPath:/csi,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-c7dsw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:*true,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},} start failed in pod csi-hostpath-resizer-0_kube-system(141cbb01-a17d-4d07-9f2b-8b3f2c341cd6): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-resizer/manifests/sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7": tls: failed to verify certificate: x509: certificate signed by unknown authority
Jul 19 16:07:17 minikube kubelet[2393]: E0719 16:07:17.363043    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-resizer\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-resizer/manifests/sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\\\": tls: failed to verify certificate: x509: certificate signed by unknown authority\"" pod="kube-system/csi-hostpath-resizer-0" podUID=141cbb01-a17d-4d07-9f2b-8b3f2c341cd6
Jul 19 16:07:19 minikube kubelet[2393]: E0719 16:07:19.439382    2393 remote_image.go:167] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-attacher/manifests/sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b"
Jul 19 16:07:19 minikube kubelet[2393]: E0719 16:07:19.439429    2393 kuberuntime_image.go:53] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-attacher/manifests/sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b"
Jul 19 16:07:19 minikube kubelet[2393]: E0719 16:07:19.439632    2393 kuberuntime_manager.go:1212] container &Container{Name:csi-attacher,Image:registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b,Command:[],Args:[--v=5 --csi-address=/csi/csi.sock],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:socket-dir,ReadOnly:false,MountPath:/csi,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-rnrlc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:*true,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},} start failed in pod csi-hostpath-attacher-0_kube-system(84a0ed60-2130-4d0a-a4f0-2f9e2d0a0796): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-attacher/manifests/sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b": tls: failed to verify certificate: x509: certificate signed by unknown authority
Jul 19 16:07:19 minikube kubelet[2393]: E0719 16:07:19.439672    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-attacher\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-attacher/manifests/sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\\\": tls: failed to verify certificate: x509: certificate signed by unknown authority\"" pod="kube-system/csi-hostpath-attacher-0" podUID=84a0ed60-2130-4d0a-a4f0-2f9e2d0a0796
Jul 19 16:07:19 minikube kubelet[2393]: E0719 16:07:19.847589    2393 remote_image.go:167] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-external-health-monitor-controller/manifests/sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-external-health-monitor-controller:v0.7.0@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c"
Jul 19 16:07:19 minikube kubelet[2393]: E0719 16:07:19.847627    2393 kuberuntime_image.go:53] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-external-health-monitor-controller/manifests/sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-external-health-monitor-controller:v0.7.0@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c"
Jul 19 16:07:19 minikube kubelet[2393]: E0719 16:07:19.847707    2393 kuberuntime_manager.go:1212] container &Container{Name:csi-external-health-monitor-controller,Image:registry.k8s.io/sig-storage/csi-external-health-monitor-controller:v0.7.0@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c,Command:[],Args:[--v=5 --csi-address=$(ADDRESS) --leader-election],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:ADDRESS,Value:/csi/csi.sock,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:socket-dir,ReadOnly:false,MountPath:/csi,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-jvjfl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},} start failed in pod csi-hostpathplugin-fxglc_kube-system(5cfdaa53-000f-4685-a113-2a7771f51bb4): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-external-health-monitor-controller/manifests/sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c": tls: failed to verify certificate: x509: certificate signed by unknown authority
Jul 19 16:07:20 minikube kubelet[2393]: E0719 16:07:20.243864    2393 remote_image.go:167] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-node-driver-registrar/manifests/sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.6.0@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c"
Jul 19 16:07:20 minikube kubelet[2393]: E0719 16:07:20.243918    2393 kuberuntime_image.go:53] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-node-driver-registrar/manifests/sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.6.0@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c"
Jul 19 16:07:20 minikube kubelet[2393]: E0719 16:07:20.244012    2393 kuberuntime_manager.go:1212] container &Container{Name:node-driver-registrar,Image:registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.6.0@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c,Command:[],Args:[--v=5 --csi-address=/csi/csi.sock --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBE_NODE_NAME,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:spec.nodeName,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:socket-dir,ReadOnly:false,MountPath:/csi,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:registration-dir,ReadOnly:false,MountPath:/registration,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:csi-data-dir,ReadOnly:false,MountPath:/csi-data-dir,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-jvjfl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:*true,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},} start failed in pod csi-hostpathplugin-fxglc_kube-system(5cfdaa53-000f-4685-a113-2a7771f51bb4): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-node-driver-registrar/manifests/sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c": tls: failed to verify certificate: x509: certificate signed by unknown authority
Jul 19 16:07:20 minikube kubelet[2393]: E0719 16:07:20.599906    2393 remote_image.go:167] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/hostpathplugin/manifests/sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/hostpathplugin:v1.9.0@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5"
Jul 19 16:07:20 minikube kubelet[2393]: E0719 16:07:20.600034    2393 kuberuntime_image.go:53] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/hostpathplugin/manifests/sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/hostpathplugin:v1.9.0@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5"
Jul 19 16:07:20 minikube kubelet[2393]: E0719 16:07:20.600195    2393 kuberuntime_manager.go:1212] container &Container{Name:hostpath,Image:registry.k8s.io/sig-storage/hostpathplugin:v1.9.0@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5,Command:[],Args:[--drivername=hostpath.csi.k8s.io --v=5 --endpoint=$(CSI_ENDPOINT) --nodeid=$(KUBE_NODE_NAME)],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:healthz,HostPort:0,ContainerPort:9898,Protocol:TCP,HostIP:,},},Env:[]EnvVar{EnvVar{Name:CSI_ENDPOINT,Value:unix:///csi/csi.sock,ValueFrom:nil,},EnvVar{Name:KUBE_NODE_NAME,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:spec.nodeName,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:socket-dir,ReadOnly:false,MountPath:/csi,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:mountpoint-dir,ReadOnly:false,MountPath:/var/lib/kubelet/pods,SubPath:,MountPropagation:*Bidirectional,SubPathExpr:,},VolumeMount{Name:plugins-dir,ReadOnly:false,MountPath:/var/lib/kubelet/plugins,SubPath:,MountPropagation:*Bidirectional,SubPathExpr:,},VolumeMount{Name:csi-data-dir,ReadOnly:false,MountPath:/csi-data-dir,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:dev-dir,ReadOnly:false,MountPath:/dev,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-jvjfl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/healthz,Port:{1 0 healthz},Host:,Scheme:HTTP,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:10,TimeoutSeconds:3,PeriodSeconds:2,SuccessThreshold:1,FailureThreshold:5,TerminationGracePeriodSeconds:nil,},ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:*true,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},} start failed in pod csi-hostpathplugin-fxglc_kube-system(5cfdaa53-000f-4685-a113-2a7771f51bb4): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/hostpathplugin/manifests/sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5": tls: failed to verify certificate: x509: certificate signed by unknown authority
Jul 19 16:07:20 minikube kubelet[2393]: E0719 16:07:20.995623    2393 remote_image.go:167] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/livenessprobe/manifests/sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/livenessprobe:v2.8.0@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0"
Jul 19 16:07:20 minikube kubelet[2393]: E0719 16:07:20.995661    2393 kuberuntime_image.go:53] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/livenessprobe/manifests/sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/livenessprobe:v2.8.0@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0"
Jul 19 16:07:20 minikube kubelet[2393]: E0719 16:07:20.995747    2393 kuberuntime_manager.go:1212] container &Container{Name:liveness-probe,Image:registry.k8s.io/sig-storage/livenessprobe:v2.8.0@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0,Command:[],Args:[--csi-address=/csi/csi.sock --health-port=9898],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:socket-dir,ReadOnly:false,MountPath:/csi,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-jvjfl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},} start failed in pod csi-hostpathplugin-fxglc_kube-system(5cfdaa53-000f-4685-a113-2a7771f51bb4): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/livenessprobe/manifests/sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0": tls: failed to verify certificate: x509: certificate signed by unknown authority
Jul 19 16:07:21 minikube kubelet[2393]: E0719 16:07:21.423851    2393 remote_image.go:167] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-provisioner/manifests/sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-provisioner:v3.3.0@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8"
Jul 19 16:07:21 minikube kubelet[2393]: E0719 16:07:21.423884    2393 kuberuntime_image.go:53] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-provisioner/manifests/sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-provisioner:v3.3.0@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8"
Jul 19 16:07:21 minikube kubelet[2393]: E0719 16:07:21.423959    2393 kuberuntime_manager.go:1212] container &Container{Name:csi-provisioner,Image:registry.k8s.io/sig-storage/csi-provisioner:v3.3.0@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8,Command:[],Args:[-v=5 --csi-address=/csi/csi.sock --feature-gates=Topology=true --enable-capacity --capacity-ownerref-level=0 --node-deployment=true --strict-topology=true --immediate-topology=false --worker-threads=5],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:NODE_NAME,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:spec.nodeName,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},EnvVar{Name:NAMESPACE,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},EnvVar{Name:POD_NAME,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.name,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:socket-dir,ReadOnly:false,MountPath:/csi,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-jvjfl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:*true,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},} start failed in pod csi-hostpathplugin-fxglc_kube-system(5cfdaa53-000f-4685-a113-2a7771f51bb4): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-provisioner/manifests/sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8": tls: failed to verify certificate: x509: certificate signed by unknown authority
Jul 19 16:07:21 minikube kubelet[2393]: E0719 16:07:21.871236    2393 remote_image.go:167] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-snapshotter/manifests/sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f"
Jul 19 16:07:21 minikube kubelet[2393]: E0719 16:07:21.871302    2393 kuberuntime_image.go:53] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-snapshotter/manifests/sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\": tls: failed to verify certificate: x509: certificate signed by unknown authority" image="registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f"
Jul 19 16:07:21 minikube kubelet[2393]: E0719 16:07:21.871536    2393 kuberuntime_manager.go:1212] container &Container{Name:csi-snapshotter,Image:registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f,Command:[],Args:[-v=5 --csi-address=/csi/csi.sock --node-deployment],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:NODE_NAME,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:spec.nodeName,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:socket-dir,ReadOnly:false,MountPath:/csi,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-jvjfl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:*true,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},} start failed in pod csi-hostpathplugin-fxglc_kube-system(5cfdaa53-000f-4685-a113-2a7771f51bb4): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-snapshotter/manifests/sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f": tls: failed to verify certificate: x509: certificate signed by unknown authority
Jul 19 16:07:21 minikube kubelet[2393]: E0719 16:07:21.871684    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"csi-external-health-monitor-controller\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-external-health-monitor-controller/manifests/sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\\\": tls: failed to verify certificate: x509: certificate signed by unknown authority\", failed to \"StartContainer\" for \"node-driver-registrar\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-node-driver-registrar/manifests/sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\\\": tls: failed to verify certificate: x509: certificate signed by unknown authority\", failed to \"StartContainer\" for \"hostpath\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/hostpathplugin/manifests/sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\\\": tls: failed to verify certificate: x509: certificate signed by unknown authority\", failed to \"StartContainer\" for \"liveness-probe\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/livenessprobe/manifests/sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\\\": tls: failed to verify certificate: x509: certificate signed by unknown authority\", failed to \"StartContainer\" for \"csi-provisioner\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-provisioner/manifests/sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\\\": tls: failed to verify certificate: x509: certificate signed by unknown authority\", failed to \"StartContainer\" for \"csi-snapshotter\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://us-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/sig-storage/csi-snapshotter/manifests/sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\\\": tls: failed to verify certificate: x509: certificate signed by unknown authority\"]" pod="kube-system/csi-hostpathplugin-fxglc" podUID=5cfdaa53-000f-4685-a113-2a7771f51bb4
Jul 19 16:07:31 minikube kubelet[2393]: E0719 16:07:31.824831    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-resizer\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\\\"\"" pod="kube-system/csi-hostpath-resizer-0" podUID=141cbb01-a17d-4d07-9f2b-8b3f2c341cd6
Jul 19 16:07:32 minikube kubelet[2393]: E0719 16:07:32.829929    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-attacher\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\\\"\"" pod="kube-system/csi-hostpath-attacher-0" podUID=84a0ed60-2130-4d0a-a4f0-2f9e2d0a0796
Jul 19 16:07:36 minikube kubelet[2393]: E0719 16:07:36.831187    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"csi-external-health-monitor-controller\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-external-health-monitor-controller:v0.7.0@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\\\"\", failed to \"StartContainer\" for \"node-driver-registrar\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.6.0@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\\\"\", failed to \"StartContainer\" for \"hostpath\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/hostpathplugin:v1.9.0@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\\\"\", failed to \"StartContainer\" for \"liveness-probe\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/livenessprobe:v2.8.0@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\\\"\", failed to \"StartContainer\" for \"csi-provisioner\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-provisioner:v3.3.0@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\\\"\", failed to \"StartContainer\" for \"csi-snapshotter\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\\\"\"]" pod="kube-system/csi-hostpathplugin-fxglc" podUID=5cfdaa53-000f-4685-a113-2a7771f51bb4
Jul 19 16:07:42 minikube kubelet[2393]: E0719 16:07:42.830202    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-resizer\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\\\"\"" pod="kube-system/csi-hostpath-resizer-0" podUID=141cbb01-a17d-4d07-9f2b-8b3f2c341cd6
Jul 19 16:07:46 minikube kubelet[2393]: E0719 16:07:46.836133    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-attacher\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\\\"\"" pod="kube-system/csi-hostpath-attacher-0" podUID=84a0ed60-2130-4d0a-a4f0-2f9e2d0a0796
Jul 19 16:07:49 minikube kubelet[2393]: E0719 16:07:49.832186    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"csi-external-health-monitor-controller\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-external-health-monitor-controller:v0.7.0@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\\\"\", failed to \"StartContainer\" for \"node-driver-registrar\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.6.0@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\\\"\", failed to \"StartContainer\" for \"hostpath\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/hostpathplugin:v1.9.0@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\\\"\", failed to \"StartContainer\" for \"liveness-probe\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/livenessprobe:v2.8.0@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\\\"\", failed to \"StartContainer\" for \"csi-provisioner\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-provisioner:v3.3.0@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\\\"\", failed to \"StartContainer\" for \"csi-snapshotter\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\\\"\"]" pod="kube-system/csi-hostpathplugin-fxglc" podUID=5cfdaa53-000f-4685-a113-2a7771f51bb4
Jul 19 16:07:54 minikube kubelet[2393]: E0719 16:07:54.825906    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-resizer\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\\\"\"" pod="kube-system/csi-hostpath-resizer-0" podUID=141cbb01-a17d-4d07-9f2b-8b3f2c341cd6
Jul 19 16:07:57 minikube kubelet[2393]: E0719 16:07:57.822789    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-attacher\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\\\"\"" pod="kube-system/csi-hostpath-attacher-0" podUID=84a0ed60-2130-4d0a-a4f0-2f9e2d0a0796
Jul 19 16:08:01 minikube kubelet[2393]: E0719 16:08:01.825719    2393 kubelet.go:1875] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[art-res-nfs], unattached volumes=[], failed to process volumes=[]: timed out waiting for the condition" pod="loco/loco-loco-emulator-0"
Jul 19 16:08:01 minikube kubelet[2393]: E0719 16:08:01.825854    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="unmounted volumes=[art-res-nfs], unattached volumes=[], failed to process volumes=[]: timed out waiting for the condition" pod="loco/loco-loco-emulator-0" podUID=a8d0493b-37e5-4e98-88b6-4d88270378ea
Jul 19 16:08:03 minikube kubelet[2393]: E0719 16:08:03.829028    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"csi-external-health-monitor-controller\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-external-health-monitor-controller:v0.7.0@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\\\"\", failed to \"StartContainer\" for \"node-driver-registrar\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.6.0@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\\\"\", failed to \"StartContainer\" for \"hostpath\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/hostpathplugin:v1.9.0@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\\\"\", failed to \"StartContainer\" for \"liveness-probe\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/livenessprobe:v2.8.0@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\\\"\", failed to \"StartContainer\" for \"csi-provisioner\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-provisioner:v3.3.0@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\\\"\", failed to \"StartContainer\" for \"csi-snapshotter\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\\\"\"]" pod="kube-system/csi-hostpathplugin-fxglc" podUID=5cfdaa53-000f-4685-a113-2a7771f51bb4
Jul 19 16:08:05 minikube kubelet[2393]: E0719 16:08:05.823712    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-resizer\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\\\"\"" pod="kube-system/csi-hostpath-resizer-0" podUID=141cbb01-a17d-4d07-9f2b-8b3f2c341cd6
Jul 19 16:08:09 minikube kubelet[2393]: E0719 16:08:09.827905    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-attacher\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\\\"\"" pod="kube-system/csi-hostpath-attacher-0" podUID=84a0ed60-2130-4d0a-a4f0-2f9e2d0a0796
Jul 19 16:08:16 minikube kubelet[2393]: E0719 16:08:16.831489    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"csi-external-health-monitor-controller\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-external-health-monitor-controller:v0.7.0@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\\\"\", failed to \"StartContainer\" for \"node-driver-registrar\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.6.0@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\\\"\", failed to \"StartContainer\" for \"hostpath\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/hostpathplugin:v1.9.0@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\\\"\", failed to \"StartContainer\" for \"liveness-probe\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/livenessprobe:v2.8.0@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\\\"\", failed to \"StartContainer\" for \"csi-provisioner\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-provisioner:v3.3.0@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\\\"\", failed to \"StartContainer\" for \"csi-snapshotter\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\\\"\"]" pod="kube-system/csi-hostpathplugin-fxglc" podUID=5cfdaa53-000f-4685-a113-2a7771f51bb4
Jul 19 16:08:18 minikube kubelet[2393]: E0719 16:08:18.822670    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-resizer\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\\\"\"" pod="kube-system/csi-hostpath-resizer-0" podUID=141cbb01-a17d-4d07-9f2b-8b3f2c341cd6
Jul 19 16:08:24 minikube kubelet[2393]: E0719 16:08:24.836093    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-attacher\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-attacher:v4.0.0@sha256:9a685020911e2725ad019dbce6e4a5ab93d51e3d4557f115e64343345e05781b\\\"\"" pod="kube-system/csi-hostpath-attacher-0" podUID=84a0ed60-2130-4d0a-a4f0-2f9e2d0a0796
Jul 19 16:08:25 minikube kubelet[2393]: E0719 16:08:25.852141    2393 mount_linux.go:232] Mount failed: exit status 32
Jul 19 16:08:25 minikube kubelet[2393]: Mounting command: mount
Jul 19 16:08:25 minikube kubelet[2393]: Mounting arguments: -t nfs nfs-server.loco.svc.cluster.local:/exports/art /var/lib/kubelet/pods/a8d0493b-37e5-4e98-88b6-4d88270378ea/volumes/kubernetes.io~nfs/art-res-nfs
Jul 19 16:08:25 minikube kubelet[2393]: Output: mount.nfs: Resource temporarily unavailable
Jul 19 16:08:25 minikube kubelet[2393]: E0719 16:08:25.852415    2393 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/nfs/a8d0493b-37e5-4e98-88b6-4d88270378ea-art-res-nfs podName:a8d0493b-37e5-4e98-88b6-4d88270378ea nodeName:}" failed. No retries permitted until 2025-07-19 16:10:27.852398882 +0000 UTC m=+4811.089749720 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "art-res-nfs" (UniqueName: "kubernetes.io/nfs/a8d0493b-37e5-4e98-88b6-4d88270378ea-art-res-nfs") pod "loco-loco-emulator-0" (UID: "a8d0493b-37e5-4e98-88b6-4d88270378ea") : mount failed: exit status 32
Jul 19 16:08:25 minikube kubelet[2393]: Mounting command: mount
Jul 19 16:08:25 minikube kubelet[2393]: Mounting arguments: -t nfs nfs-server.loco.svc.cluster.local:/exports/art /var/lib/kubelet/pods/a8d0493b-37e5-4e98-88b6-4d88270378ea/volumes/kubernetes.io~nfs/art-res-nfs
Jul 19 16:08:25 minikube kubelet[2393]: Output: mount.nfs: Resource temporarily unavailable
Jul 19 16:08:29 minikube kubelet[2393]: E0719 16:08:29.840810    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"csi-external-health-monitor-controller\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-external-health-monitor-controller:v0.7.0@sha256:80b9ba94aa2afe24553d69bd165a6a51552d1582d68618ec00d3b804a7d9193c\\\"\", failed to \"StartContainer\" for \"node-driver-registrar\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.6.0@sha256:f1c25991bac2fbb7f5fcf91ed9438df31e30edee6bed5a780464238aa09ad24c\\\"\", failed to \"StartContainer\" for \"hostpath\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/hostpathplugin:v1.9.0@sha256:92257881c1d6493cf18299a24af42330f891166560047902b8d431fb66b01af5\\\"\", failed to \"StartContainer\" for \"liveness-probe\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/livenessprobe:v2.8.0@sha256:cacee2b5c36dd59d4c7e8469c05c9e4ef53ecb2df9025fa8c10cdaf61bce62f0\\\"\", failed to \"StartContainer\" for \"csi-provisioner\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-provisioner:v3.3.0@sha256:ee3b525d5b89db99da3b8eb521d9cd90cb6e9ef0fbb651e98bb37be78d36b5b8\\\"\", failed to \"StartContainer\" for \"csi-snapshotter\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0@sha256:291334908ddf71a4661fd7f6d9d97274de8a5378a2b6fdfeb2ce73414a34f82f\\\"\"]" pod="kube-system/csi-hostpathplugin-fxglc" podUID=5cfdaa53-000f-4685-a113-2a7771f51bb4
Jul 19 16:08:32 minikube kubelet[2393]: E0719 16:08:32.837631    2393 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"csi-resizer\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/sig-storage/csi-resizer:v1.6.0@sha256:425d8f1b769398127767b06ed97ce62578a3179bcb99809ce93a1649e025ffe7\\\"\"" pod="kube-system/csi-hostpath-resizer-0" podUID=141cbb01-a17d-4d07-9f2b-8b3f2c341cd6

* 
* ==> storage-provisioner [770f516908d0] <==
* I0719 14:50:31.126208       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0719 14:50:31.133146       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0719 14:50:31.133195       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0719 14:50:31.138074       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0719 14:50:31.138179       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_1019c04e-964e-42ee-ba58-023c7a0910eb!
I0719 14:50:31.138648       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"ef13bf06-6e6c-44e9-9cdb-a09f65100fd8", APIVersion:"v1", ResourceVersion:"506", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_1019c04e-964e-42ee-ba58-023c7a0910eb became leader
I0719 14:50:31.238740       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_1019c04e-964e-42ee-ba58-023c7a0910eb!
I0719 15:03:58.896660       1 controller.go:1332] provision "loco/nfs-pvc" class "standard": started
I0719 15:03:58.897133       1 event.go:282] Event(v1.ObjectReference{Kind:"PersistentVolumeClaim", Namespace:"loco", Name:"nfs-pvc", UID:"b05d02c7-728d-467c-bfa2-324afaa6e099", APIVersion:"v1", ResourceVersion:"1434", FieldPath:""}): type: 'Normal' reason: 'Provisioning' External provisioner is provisioning volume for claim "loco/nfs-pvc"
I0719 15:03:58.896767       1 storage_provisioner.go:61] Provisioning volume {&StorageClass{ObjectMeta:{standard    80b1f1f0-3db6-43e5-9cdf-9271aabea333 299 0 2025-07-19 14:50:17 +0000 UTC <nil> <nil> map[addonmanager.kubernetes.io/mode:EnsureExists] map[kubectl.kubernetes.io/last-applied-configuration:{"apiVersion":"storage.k8s.io/v1","kind":"StorageClass","metadata":{"annotations":{"storageclass.kubernetes.io/is-default-class":"true"},"labels":{"addonmanager.kubernetes.io/mode":"EnsureExists"},"name":"standard"},"provisioner":"k8s.io/minikube-hostpath"}
 storageclass.kubernetes.io/is-default-class:true] [] []  [{kubectl-client-side-apply Update storage.k8s.io/v1 2025-07-19 14:50:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:kubectl.kubernetes.io/last-applied-configuration":{},"f:storageclass.kubernetes.io/is-default-class":{}},"f:labels":{".":{},"f:addonmanager.kubernetes.io/mode":{}}},"f:provisioner":{},"f:reclaimPolicy":{},"f:volumeBindingMode":{}}}]},Provisioner:k8s.io/minikube-hostpath,Parameters:map[string]string{},ReclaimPolicy:*Delete,MountOptions:[],AllowVolumeExpansion:nil,VolumeBindingMode:*Immediate,AllowedTopologies:[]TopologySelectorTerm{},} pvc-b05d02c7-728d-467c-bfa2-324afaa6e099 &PersistentVolumeClaim{ObjectMeta:{nfs-pvc  loco  b05d02c7-728d-467c-bfa2-324afaa6e099 1434 0 2025-07-19 15:03:58 +0000 UTC <nil> <nil> map[app.kubernetes.io/managed-by:Helm] map[meta.helm.sh/release-name:loco meta.helm.sh/release-namespace:loco volume.beta.kubernetes.io/storage-provisioner:k8s.io/minikube-hostpath volume.kubernetes.io/storage-provisioner:k8s.io/minikube-hostpath] [] [kubernetes.io/pvc-protection]  [{helm Update v1 2025-07-19 15:03:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:meta.helm.sh/release-name":{},"f:meta.helm.sh/release-namespace":{}},"f:labels":{".":{},"f:app.kubernetes.io/managed-by":{}}},"f:spec":{"f:accessModes":{},"f:resources":{"f:requests":{".":{},"f:storage":{}}},"f:storageClassName":{},"f:volumeMode":{}}}} {kube-controller-manager Update v1 2025-07-19 15:03:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:volume.beta.kubernetes.io/storage-provisioner":{},"f:volume.kubernetes.io/storage-provisioner":{}}}}}]},Spec:PersistentVolumeClaimSpec{AccessModes:[ReadWriteOnce],Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{storage: {{10737418240 0} {<nil>} 10Gi BinarySI},},},VolumeName:,Selector:nil,StorageClassName:*standard,VolumeMode:*Filesystem,DataSource:nil,},Status:PersistentVolumeClaimStatus{Phase:Pending,AccessModes:[],Capacity:ResourceList{},Conditions:[]PersistentVolumeClaimCondition{},},} nil} to /tmp/hostpath-provisioner/loco/nfs-pvc
I0719 15:03:58.897774       1 controller.go:1439] provision "loco/nfs-pvc" class "standard": volume "pvc-b05d02c7-728d-467c-bfa2-324afaa6e099" provisioned
I0719 15:03:58.897800       1 controller.go:1456] provision "loco/nfs-pvc" class "standard": succeeded
I0719 15:03:58.897803       1 volume_store.go:212] Trying to save persistentvolume "pvc-b05d02c7-728d-467c-bfa2-324afaa6e099"
I0719 15:03:58.901272       1 volume_store.go:219] persistentvolume "pvc-b05d02c7-728d-467c-bfa2-324afaa6e099" saved
I0719 15:03:58.901480       1 event.go:282] Event(v1.ObjectReference{Kind:"PersistentVolumeClaim", Namespace:"loco", Name:"nfs-pvc", UID:"b05d02c7-728d-467c-bfa2-324afaa6e099", APIVersion:"v1", ResourceVersion:"1434", FieldPath:""}): type: 'Normal' reason: 'ProvisioningSucceeded' Successfully provisioned volume pvc-b05d02c7-728d-467c-bfa2-324afaa6e099

